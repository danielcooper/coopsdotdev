---
title: Stop being weird about AI
---

![Scrum](/assets/images/truck.gif)


As I sit here and wonder if I really should let Kiro (which is very good btw) run whatever python script it fancies, it's hard not to notice just how big a change we've all been dealing with in the past year is. 50 years of hard won engineering lessions may well be going up in smoke. Which is exciting and concerning in equal measure.

But we're in a moment with AI dev tooling where engineering leaders are starting to be done with "let’s experiment" and have started to go “why aren’t you using it yet?”

It doesn’t seem to matter that most of them don’t actually do the job any more. They’re not writing the code, reviewing the PRs, or on call for the thing. But they’re happy to set usage targets for a tool they’ve never had to rely on in production.

AI isn’t just encouraged. It’s expected. Some teams are tracking usage like it’s a KPI. Others are “having conversations” with people who aren’t using it enough. We’ve basically invented AI absenteeism.

The trouble is, product outcomes don’t automatically improve just because a tool got used. You can crank out AI-assisted commits all day and still ship something slow, awkward, or confusing. Usage is not value. All it measures is whether the magic button got pressed, not whether the thing you built is better for it.

And on the other side, you’ve some got engineers digging in. Refusing to touch it. Treating AI like a party trick for people who can’t code. Acting as if ignoring it will make it go away. Or that it's a battle between endless slop or their otherwise excellent (lol) code.

The distance between those two camps keeps growing. One side pushing harder and harder for something they can’t meaningfully measure. The other side closing themselves off from a change that could reshape their work.

## We’ve been here before

Whenever something big and awkward lands in tech, we swing wildly. Half the industry falls in love and starts writing manifestos. The other half pretends it’s irrelevant until it’s too late.

We did it with crypto. The blockchain was a clever, novel way to record and verify transactions. Then it became a religion, a scam carnival, a get-rich-quick scheme for people that don't like art. We stopped talking about the ledger as a tool and started treating it like a belief system. You remember the Linkedin posts.

Now we’re doing it again with AI. The conversation has become culture war. Neither gets us closer to understanding where it’s actually useful.

## The measurement fantasy

The Mythical Man-Month came out in 1975. Nearly **fifty years** later, the lesson still has n’t landed: software engineering doesn’t scale like factory work. Productivity in this field is messy, contextual, and hard to quantify. Fred Brooks warned that adding people to a late project makes it later. We’ve spent the decades since proving him right while trying to find a metric that will make the problem go away.

We’ve tried them all. Lines of code, story points, tickets closed, commits per week, PRs merged, even tracking keyboard time like a Victorian mill manager (ok, loomer). They’re proxies, and mostly bad ones. They measure motion, not impact. You can rack up impressive numbers building something no one needs or fixing things no one notices.

If we haven’t cracked a reliable way to measure engineering output in half a century, you are your Dog petting AI startup are not going to invent it by counting how many times someone clicks “Ask AI.”

## The slop fallacy

Yes, AI code has problems. Big, big ones. Well documented so I wont bother going in to them here. You and I both know that the person claiming to have vibed their whole startup has vibed a box of knifes.

But writing it off wholesale as "slop" is lazy. Your job as an engineer is to make things better. Stay curious. Prod at the edges. Figure out where it’s useful, where it’s dangerous, and how to close the gap between the two.

Hell, you could argue that’s the job of an engineer in any field taking the imperfect and making it work. It's a disciplin of constraints and inventions to overcome those. Bridges aren’t built from flawless steel, and planes aren’t carved out of one perfect block of aluminium. You work with what you’ve got, and you improve it until it’s fit for purpose. So the attitude of "it's not perfect so I'm not going to use it"? Come on.

## So where does that leave us?

AI in engineering isn’t magic, but it’s not nothing either. It’s another imperfect tool in a field built entirely on imperfect tools. Treating usage as success is a fantasy. Writing it off as slop is a cop-out.

The real work is somewhere in between: figuring out where it helps, where it hurts, and how to make it less of the latter and more of the former. That takes curiosity, discipline, and the willingness to wrestle with messy, unpredictable results.

Fifty years of engineering lessons aren’t going up in smoke. They are being tested again. Same as they were when we swapped punch cards for terminals, or servers for the cloud. We’ve always been here. The tools change. The job doesn’t.

So stop being so weird about AI.